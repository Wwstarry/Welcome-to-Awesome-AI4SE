# üåü Welcome-to-Awesome-AI4SE
<a name="top"></a>

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re) ![PRs Welcome](https://img.shields.io/badge/PRs-Welcome-brightgreen) ![Last Updated](https://img.shields.io/badge/Last%20Updated-June%2030,%202025-blue)


*I hope to maintain a curated AI4SE Paper Repository collecting recent high-quality research in software engineering. It aims to help researchers and practitioners stay updated with cutting-edge trends.*



## üóìÔ∏è 2025

- [2025-06-26] [ConTested: Consistency-Aided Tested Code Generation with LLM](https://conf.researchr.org/details/issta-2025/issta-2025-papers/27/ConTested-Consistency-Aided-Tested-Code-Generation-with-LLM)  
  *Incorporate user feedback to effectively guide consistency.*

- [2025-06-19] [Beyond PEFT: Layer-Wise Optimization for More Effective and Efficient Large Code Model Tuning](https://dl.acm.org/doi/10.1145/3729341)  
  *A comprehensive study on exploring the effectiveness of the PEFT methods.*

- [2025-05-02] [Iterative Generation of Adversarial Example for Deep Code Models](https://conf.researchr.org/details/icse-2025/icse-2025-research-track/77/Iterative-Generation-of-Adversarial-Example-for-Deep-Code-Models)  
  *A novel black-box adversarial example generation method that iteratively utilizes feedback from failed attacks to refine the generation process.*

- [2025-04-30] [Planning a Large Language Model for Static Detection of Runtime Errors in Code Snippets](https://ieeexplore.ieee.org/document/11029953)  
  *Instruct an LLM to autonomously formulate a plan to navigate through a control flow graph (CFG) for predictive execution of (in)complete code snippets.*


- [2025-04-21] [Can LLMs Replace Human Evaluators? An Empirical Study of LLM-as-a-Judge in Software Engineering](https://arxiv.org/pdf/2502.06193)  
  *Explore LLM-as-a-judge methods for evaluating SE tasks.*

- [2025-03-22] [ROCODE: Integrating Backtracking Mechanism and Program Analysis in Large Language Models for Code Generation](https://arxiv.org/pdf/2411.07112)  
  *Integrate backtracking mechanism and program analysis tools.*

- [2025-03-18] [HumanEvo: An Evolution-aware Benchmark for More Realistic Evaluation of Repository-level Code Generation](https://arxiv.org/pdf/2406.06918)  
  *Construct an evolution-aware repository-level code generation dataset.*

- [2025-02-13] [Knowledge-Enhanced Program Repair for Data Science Code](https://arxiv.org/pdf/2502.09771)  
  *A knowledge-enhanced program repair approach designed to repair the buggy code generated by LLMs in the data science domain.*

- [2025-02-05] [COFFE: A Code Efficiency Benchmark for Code Generation](https://arxiv.org/pdf/2502.02827)  
  *A new benchmark COFFE for the time efficiency evaluation of LLMgenerated code.*

- [2025-02-01] [Patch Synthesis for Property Repair of Deep Neural Networks](https://arxiv.org/pdf/2404.01642)  
  *Incorporate formal verification and a heuristic mechanism for allocating patch modules.*

- [2025-01-04] [CoreCodeBench: A Configurable Multi-Scenario Repository-Level Benchmark](https://arxiv.org/pdf/2507.05281)  
  *Provide a comprehensive and extensive repository-level benchmark to investigate the applicability of LLMs in real-world engineering projects.*






## üóìÔ∏è 2024


- [2024-11-12] [Qwen2.5-Coder Technical Report](https://arxiv.org/pdf/2409.12186)  
  *Introduce the Qwen2.5-Coder series.*


- [2024-11-11] [SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering](https://arxiv.org/pdf/2405.15793)  
  *A system that facilitates LM agents to autonomously use computers to solve software engineering tasks.*

- [2024-10-29] [AGENTLESS: Demystifying LLM-based Software Engineering Agents](https://arxiv.org/pdf/2407.01489)  
  *Do we really have to employ complex autonomous software agents?*


- [2024-09-21] [Reasoning Runtime Behavior of a Program with LLM: How Far Are We?](https://arxiv.org/pdf/2403.16437)  
  *Evaluate the code reasoning capability of code LLMs.*



- [2024-08-22] [Search-Based LLMs for Code Optimization](https://arxiv.org/pdf/2408.12159)  
  *Integrate LLMs with evolutionary search.*

- [2024-07-28] [RLCoder: Reinforcement Learning for Repository-Level Code Completion](https://arxiv.org/pdf/2407.19487)  
  *A novel reinforcement learning framework for repository-level code completion.*

- [2024-06-30] [GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding](https://arxiv.org/abs/2406.14572)  
  *Align graph-level semantics with code generation models.*

- [2024-06-28] [Context-Augmented Code Generation Using Programming Knowledge Graphs](https://arxiv.org/abs/2406.14001)  
  *Leverage knowledge graphs to improve context-aware generation.*

- [2024-06-27] [From Token to Line: Enhancing Code Generation with a Long-Term Perspective](https://arxiv.org/abs/2406.13456)  
  *Model code generation at the line-level for long-range coherence.*

- [2024-06-25] [Brevity is the soul of wit: Pruning long files for code generation](https://arxiv.org/abs/2406.09876)  
  *File pruning strategies help LLMs focus and generate better code.*

- [2024-06-24] [What to Retrieve for Effective Retrieval-Augmented Code Generation? An Empirical Study and Beyond](https://arxiv.org/abs/2406.12345)  
  *Compares various retrieval signals for code generation.*

- [2024-06-22] [Uncertainty-Guided Chain-of-Thought for Code Generation with LLMs](https://arxiv.org/abs/2406.11599)  
  *Use uncertainty to dynamically guide CoT prompting for code.*

- [2024-06-21] [Sifting through the Chaff: On Utilizing Execution Feedback for Ranking the Generated Code Candidates](https://arxiv.org/abs/2406.11777)  
  *Execution-based ranking improves selection of code completions.*

- [2024-06-20] [AceReason-Nemotron 1.1: Advancing Math and Code Reasoning through SFT and RL Synergy](https://arxiv.org/abs/2406.11256)  
  *Combines supervised fine-tuning and RL to boost code/math reasoning.*

- [2024-06-18] [Scattered Forest Search: Smarter Code Space Exploration with LLMs](https://arxiv.org/abs/2406.08888)  
  *Explores diverse code candidates using scattered sampling.*

- [2024-06-15] [FAIT: Fault-Aware Fine-Tuning for Better Code Generation](https://arxiv.org/abs/2406.07987)  
  *Incorporate fault signals in training to boost generation quality.*

- [2024-06-10] [GiFT: Gibbs Fine-Tuning for Code Generation](https://arxiv.org/abs/2406.06100)  
  *A sampling-based fine-tuning method for code generation.*

- [2024-06-08] [SemAgent: A Semantics Aware Program Repair Agent](https://arxiv.org/abs/2406.05500)  
  *Program repair guided by semantics and repository feedback.*

- [2024-06-07] [XFT: Unlocking the Power of Code Instruction Tuning by Simply Merging Upcycled Mixture-of-Experts](https://arxiv.org/abs/2406.03400)  
  *Merge multiple experts in instruction tuning for code generation.*

- [2024-06-06] [Planning In Natural Language Improves LLM Search For Code Generation](https://arxiv.org/abs/2406.04912)  
  *Use natural language planning to guide better code retrieval.*

- [2024-06-05] [CCT: Code Comparison Tuning for Code Large Language Models](https://arxiv.org/abs/2406.03003)  
  *Code comparison-based contrastive tuning for code understanding.*

- [2024-06-03] [RepoMaster: Autonomous Exploration and Understanding of GitHub Repositories for Complex Task Solving](https://arxiv.org/abs/2406.02472)  
  *Agent framework that explores and reasons over full repositories.*

- [2024-06-01] [Quality Assessment of Prompts Used in Code Generation](https://arxiv.org/abs/2406.00084)  
  *Prompt quality evaluation for better code generation outputs.*

- [2024-05-31] [OpenCodeInstruct: A Large-scale Instruction Tuning Dataset for Code LLMs](https://arxiv.org/abs/2405.19972)  
  *Release a massive instruction tuning dataset for code generation.*

- [2024-05-30] [MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning](https://arxiv.org/abs/2405.19387)  
  *Apply multitask fine-tuning to improve code generation performance.*

- [2024-05-28] [No Man is an Island: Towards Fully Automatic Programming by Code Search, Code Generation and Program Repair](https://arxiv.org/abs/2405.17192)  
  *Integrates search, generation, and repair for fully automatic coding.*

- [2024-05-25] [EpiCoder: Encompassing Diversity and Complexity in Code Generation](https://arxiv.org/abs/2405.14555)  
  *Embrace diverse and complex cases to improve code synthesis.*

- [2024-05-23] [Code Less, Align More: Efficient LLM Fine-tuning for Code Generation with Data Pruning](https://arxiv.org/abs/2405.13897)  
  *Use high-quality data pruning to achieve efficient fine-tuning.*

- [2024-05-22] [CodeAct: Executable Code Actions Elicit Better LLM Agents](https://arxiv.org/abs/2405.13101)  
  *Executable feedback helps code agents better understand actions.*

- [2024-05-21] [Code Needs Comments: Enhancing Code LLMs with Comment Augmentation](https://arxiv.org/abs/2405.12311)  
  *Improve code generation by adding comment-based data augmentation.*

- [2024-05-20] [SemCoder: Training Code Language Models with Comprehensive Semantics Reasoning](https://arxiv.org/abs/2405.11811)  
  *Augment code LLMs with semantic reasoning capability.*

- [2024-05-19] [Self-Explained Keywords Empower Large Language Models for Code Generation](https://arxiv.org/abs/2405.11111)  
  *Add self-explained keywords to prompts to improve LLM coding.*

- [2024-05-17] [Intention is All You Need: Refining Your Code from Your Intention](https://arxiv.org/abs/2405.09597)  
  *Code refinement by intention-driven instruction and planning.*

- [2024-04-23] [UniCoder: Scaling Code Large Language Model via Universal Code](https://arxiv.org/abs/2404.10045)  
  *Unified format for multilingual and multi-paradigm code modeling.*

- [2024-04-10] [Large Language Models for Software Engineering: A Systematic Literature Review](https://arxiv.org/pdf/2308.10620)  
  *A systematic literature review (SLR) on LLM4SE.*
  

- [2024-04-03] [From Symbolic Tasks to Code Generation: Diversification Yields Better Task Performers](https://arxiv.org/abs/2404.01888)  
  *Task diversity leads to stronger generalization in code LLMs.*

- [2024-03-12] [PanGu-Coder2: Boosting Large Language Models for Code with Ranking Feedback](https://arxiv.org/abs/2403.07785)  
  *Leverage ranking-based feedback to enhance code LLM training.*

- [2024-02-23] [CoderEval: A Benchmark of Pragmatic Code Generation with Generative Pre-trained Models](https://arxiv.org/pdf/2507.05281)  
  *A new benchmark to evaluate a model‚Äôs effectiveness in pragmatic code generation scenarios.*

- [2024-02-14] [CodeFort: Robust Training for Code Generation Models](https://arxiv.org/abs/2402.07265)  
  *Improve code model robustness by curriculum and noise-aware learning.*

- [2024-01-30] [Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers](https://arxiv.org/pdf/2401.06461)  
  *Study the specific patterns that characterize machine- and human-authored code.*

## üóìÔ∏è 2023

- [2023-12-07] [SAT: Structure-aware Fine-tuning for Code Pre-trained Models](https://arxiv.org/abs/2312.04470)  
  *Incorporates structure information in fine-tuning code models.*

- [2023-10-30] [Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation](https://arxiv.org/pdf/2305.01210)  
  *EvalPlus‚Äî‚Äîa code synthesis evaluation framework to rigorously benchmark the functional correctness of LLM-synthesized code. üåüThis is **the first academic paper** I've ever read in my life, and it marks the beginning of my journey into research and academia.*



- [2023-10-23] [OctoPack: Instruction Tuning Code Large Language Models](https://arxiv.org/abs/2310.12897)  
  *Instruction tuning dataset and methodology for training code LLMs.*

- [2023-10-20] [RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation](https://arxiv.org/pdf/2303.12570)  
  *A straightforward and effective framework for the repositorylevel code completion task.*

- [2023-10-11] [The Impact of Code Data on Language Models](https://arxiv.org/pdf/2310.06830v2)  
  *A systematic investigation of how varying code data proportions in pretraining affect language models‚Äô performance across structural, arithmetic, and natural language tasks.*


- [2023-10-11] [Magicoder: Empowering Code Generation with OSS-Instruct](https://arxiv.org/abs/2310.06870)  
  *Open-source instruction-tuned dataset for better code generation.*

- [2023-09-27] [At Which Training Stage Does Code Data Help LLMs Reasoning](https://arxiv.org/abs/2309.14589)  
  *Empirical study on when code data benefits reasoning during pretraining.*

- [2023-08-24] [Code Summarization Beyond Function Level](https://arxiv.org/abs/2308.13365)  
  *Explore summarization of class- and repo-level code.*

- [2023-06-19] [CoSS: Leveraging Statement Semantics for Code Summarization](https://arxiv.org/abs/2306.10995)  
  *Uses statement-level semantics graph for better code summarization.*

- [2023-06-14] [WizardCoder: Empowering Code Large Language Models with Evol-Instruct](https://arxiv.org/abs/2306.08568)  
  *Enhance code LLMs with instruction tuning using evol-instruct strategy.*

## üöÄ Useful GitHub Repos & Models

Here are some great open-source resources and models related to **AI4SE** that are worth checking out:

-  **[SWE-bench](https://github.com/princeton-nlp/SWE-bench)**  
  A benchmark for evaluating LLMs on real-world GitHub issue resolution.  

-  **[Awesome-Code-LLM](https://github.com/codefuse-ai/Awesome-Code-LLM?tab=readme-ov-file#25-reinforcement-learning-on-code)**  
  A curated list of language modeling researches for code (and other software engineering activities), plus related datasets.  
  üåü I‚Äôll go through all the papers in this list within a month and regularly update the repo with the most valuable ones.



## üì¨ Contact

üí° **Working on something exciting in AI4SE?** I'd love to hear from you ‚Äî feel free to get in touch: panruwei@stu.cqu.edu.cn

üå± I'm currently exploring internship opportunities where I can contribute to real-world applications of AI for Software Engineering. Let's connect!


